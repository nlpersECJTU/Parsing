# Parsing

- Tree Transformer: Integrating Tree Structures into Self-Attention (EMNLp2019) [Paper](https://arxiv.org/pdf/1909.06639.pdf) | [Code](https://github.com/yaushian/Tree-Transformer) 

  论文尝试将句法信息融入到Transformer中，赋予attention更好的解释性。同时可以无监督的预测出句子的句法树，并且相比于一般的Transformer，语言模型的性能有所提高。 
